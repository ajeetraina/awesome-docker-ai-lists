name: Docker AI/ML Resource Crawler

on:
  schedule:
    # Run weekly on Monday at 00:00 UTC
    - cron: '0 0 * * 1'
  workflow_dispatch:
    # Manual trigger

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r scripts/requirements.txt

      - name: Run GitHub crawler
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # First combine the two parts of the crawler script
          cat scripts/github_crawler.py scripts/github_crawler_part2.py > scripts/crawler_combined.py
          python scripts/crawler_combined.py --days 7 --limit 30

      - name: Output summary
        run: |
          echo "Crawler job completed. Check open pull requests for new additions."
